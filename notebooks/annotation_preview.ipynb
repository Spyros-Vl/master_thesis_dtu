{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image tag parsing and annotation preview\n",
    "Version 2021-01-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Select data location\n",
    "\n",
    "Set *root_dir* to point to \"Supervisely\" project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations: 15327\n"
     ]
    }
   ],
   "source": [
    "#Set path to root dir (wrist folder)\n",
    "root_dir = pathlib.Path('../literature/Other/supervisely')\n",
    "\n",
    "# Path to annotation dir\n",
    "ann_dir = pathlib.Path(root_dir, 'wrist/ann')\n",
    "\n",
    "# Path to image dir\n",
    "img_dir = pathlib.Path(root_dir, 'wrist/img')\n",
    "\n",
    "# Lists\n",
    "list_files = lambda start_dir: [str(item) for item in start_dir.iterdir()]\n",
    "ann_list = list_files(ann_dir)\n",
    "img_list = list_files(img_dir)\n",
    "print('Number of annotations: {}'.format(len(ann_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory of this project is: c:\\Users\\spiro\\OneDrive\\Υπολογιστής\\Thesis\\Project\\master_thesis_dtu\\notebooks\n",
      "The root dir selected is: ..\\literature\\Other\\supervisely\n",
      "The annotation dir selected is: ..\\literature\\Other\\supervisely\\wrist\\ann\n",
      "The image dir selected is: ..\\literature\\Other\\supervisely\\wrist\\img\n"
     ]
    }
   ],
   "source": [
    "print(\"The working directory of this project is:\", os.getcwd())\n",
    "print(\"The root dir selected is:\", root_dir)\n",
    "print(\"The annotation dir selected is:\", ann_dir)\n",
    "print(\"The image dir selected is:\", img_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used to parse and preview data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that is parsing json file and printing all usefull data\n",
    "def parse_json(path_to_annotation):\n",
    "    #Load data\n",
    "    with open(path_to_annotation) as json_file:  \n",
    "        # Load json\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        # Print tags:\n",
    "        print('Tags:')\n",
    "        for tag in data['tags']:\n",
    "            print(tag)\n",
    "            \n",
    "        print('*******************')\n",
    "        print('Objects:')\n",
    "        #Print objects:\n",
    "        for object_dict in data['objects']:\n",
    "            print('Object type: {}\\nObject points: {}'.format(object_dict['classTitle'], \n",
    "                                                                   object_dict['points']['exterior']))\n",
    "            print('*******************')    \n",
    "            \n",
    "\n",
    "def display_annotations(path_to_annotation, image_dir, objectname, scale = 1):\n",
    "    #Load data\n",
    "    with open(path_to_annotation) as json_file:\n",
    "        \n",
    "        # Get name of the file\n",
    "        name = pathlib.PurePath(path_to_annotation).name.split('.')[0]\n",
    "        image = image_dir / (str(name) + '.png')\n",
    "\n",
    "        # Load image\n",
    "        original_image = cv2.imread(str(image))\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        annotated_image = original_image.copy()\n",
    "        \n",
    "        # Load json\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        # Draw fractures\n",
    "        for object_dict in data['objects']:\n",
    "            # Check if object is fracture\n",
    "            if object_dict['classTitle'] == objectname:\n",
    "               \n",
    "                # Get points and convert them to int for display purposes\n",
    "                top_left_point, bottom_right_point = object_dict['points']['exterior']\n",
    "                top_left_point = list(map(int,top_left_point))\n",
    "                bottom_right_point = list(map(int, bottom_right_point))\n",
    "                \n",
    "                # Draw points\n",
    "                cv2.rectangle(annotated_image, (top_left_point[0], top_left_point[1]), \n",
    "                              (bottom_right_point[0], bottom_right_point[1]), (0, 0, 255), 5)\n",
    "        \n",
    "        # Scale images for display purposes\n",
    "        original_image = cv2.resize(original_image, (0,0), fx=scale, fy=scale) \n",
    "        annotated_image = cv2.resize(annotated_image, (0,0), fx=scale, fy=scale) \n",
    "        \n",
    "        # Display images\n",
    "        cv2.imshow('Original', original_image)\n",
    "        cv2.imshow('Annotated', annotated_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "\n",
    "Select index name of the image/object that you want to preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags:\n",
      "{'name': 'ao_classification', 'value': '23-M/3.1'}\n",
      "cast\n",
      "projection_ap\n",
      "side_right\n",
      "*******************\n",
      "Objects:\n",
      "Object type: text\n",
      "Object points: [[613.0, 335.0], [706.0, 455.0]]\n",
      "*******************\n",
      "Object type: fracture\n",
      "Object points: [[229.48664474487305, 630.7427520751953], [330.1251106262207, 710.4746551513672]]\n",
      "*******************\n",
      "Object type: fracture\n",
      "Object points: [[348.0, 746.0], [429.0, 825.0]]\n",
      "*******************\n",
      "Object type: axis\n",
      "Object points: [[306.0, 856.0], [488.0, 30.0]]\n",
      "*******************\n"
     ]
    }
   ],
   "source": [
    "# Select index of the image to preview\n",
    "index = 53\n",
    "objectname = 'fracture'\n",
    "\n",
    "# To close images press any key\n",
    "parse_json(ann_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_annotations(ann_list[index], img_dir, objectname, scale = 0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix annotations containing only fracture boxes and labes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns the label and annotation for each instance\n",
    "def get_targets(path_to_annotation):\n",
    "    #Load data\n",
    "    targets = []\n",
    "    with open(path_to_annotation) as json_file:  \n",
    "        # Load json\n",
    "        data = json.load(json_file)\n",
    "        d = {}\n",
    "        \n",
    "        for object_dict in data['objects']:\n",
    "            # Check if object contains any fractures \n",
    "\n",
    "            box = []\n",
    "\n",
    "            if object_dict['classTitle'] == \"fracture\":\n",
    "                # Get points and convert them to int for display purposes\n",
    "                top_left_point, bottom_right_point = object_dict['points']['exterior']\n",
    "                top_left_point = list(map(int,top_left_point))\n",
    "                bottom_right_point = list(map(int, bottom_right_point))\n",
    "                box = (top_left_point+bottom_right_point)\n",
    "                d['boxes'] = torch.FloatTensor(box)\n",
    "                d['labels'] = \"fracture\"\n",
    "                targets.append(d)\n",
    "        \n",
    "        if not d:\n",
    "            d['labels'] = \"no_fracture\"\n",
    "            d['boxes'] =  torch.zeros(4)\n",
    "            targets.append(d)\n",
    "\n",
    "    return targets\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([213., 627., 288., 715.]), 'labels': 'fracture'},\n",
       " {'boxes': tensor([213., 627., 288., 715.]), 'labels': 'fracture'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(ann_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spiro\\OneDrive\\Υπολογιστής\\Thesis\\Project\\master_thesis_dtu\\notebooks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "print(os.getcwd())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data.my_dataset import XRayDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = XRayDataSet(pathlib.Path('../literature/Other/supervisely/wrist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4,collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\spiro\\OneDrive\\Υπολογιστής\\Thesis\\Project\\master_thesis_dtu\\notebooks\\annotation_preview.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/spiro/OneDrive/%CE%A5%CF%80%CE%BF%CE%BB%CE%BF%CE%B3%CE%B9%CF%83%CF%84%CE%AE%CF%82/Thesis/Project/master_thesis_dtu/notebooks/annotation_preview.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(training_dataloader))\n",
      "File \u001b[1;32mc:\\Users\\spiro\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\spiro\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\spiro\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\spiro\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\spiro\\OneDrive\\Υπολογιστής\\Thesis\\Project\\master_thesis_dtu\\src\\data\\my_dataset.py:36\u001b[0m, in \u001b[0;36mXRayDataSet.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     33\u001b[0m obj_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(img)\n\u001b[0;32m     35\u001b[0m \u001b[39m# Load json\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(ann_path)\n\u001b[0;32m     38\u001b[0m num_objs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(obj_ids)\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m object_dict \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     42\u001b[0m     \u001b[39m# Check if object contains any fractures \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\anaconda3\\lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m     \u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[0;32m    294\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, object_hook\u001b[39m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39mparse_float, parse_int\u001b[39m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39mparse_constant, object_pairs_hook\u001b[39m=\u001b[39mobject_pairs_hook, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b00de58b91327812a3543b0a54b44486ebb363ab132784d28226d0402cd7527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
