{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image tag parsing and annotation preview\n",
    "Version 2021-01-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Select data location\n",
    "\n",
    "Set *root_dir* to point to \"Supervisely\" project folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations: 20327\n"
     ]
    }
   ],
   "source": [
    "#Set path to root dir (wrist folder)\n",
    "root_dir = pathlib.Path('../literature/Other/supervisely')\n",
    "\n",
    "# Path to annotation dir\n",
    "ann_dir = pathlib.Path(root_dir, 'wrist/ann')\n",
    "\n",
    "# Path to image dir\n",
    "img_dir = pathlib.Path(root_dir, 'wrist/img')\n",
    "\n",
    "# Lists\n",
    "list_files = lambda start_dir: [str(item) for item in start_dir.iterdir()]\n",
    "ann_list = list_files(ann_dir)\n",
    "img_list = list_files(img_dir)\n",
    "print('Number of annotations: {}'.format(len(ann_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory of this project is: c:\\Users\\spiro\\OneDrive\\Υπολογιστής\\Thesis\\Project\\master_thesis_dtu\\notebooks\n",
      "The root dir selected is: ..\\literature\\Other\\supervisely\n",
      "The annotation dir selected is: ..\\literature\\Other\\supervisely\\wrist\\ann\n",
      "The image dir selected is: ..\\literature\\Other\\supervisely\\wrist\\img\n"
     ]
    }
   ],
   "source": [
    "print(\"The working directory of this project is:\", os.getcwd())\n",
    "print(\"The root dir selected is:\", root_dir)\n",
    "print(\"The annotation dir selected is:\", ann_dir)\n",
    "print(\"The image dir selected is:\", img_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions used to parse and preview data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that is parsing json file and printing all usefull data\n",
    "def parse_json(path_to_annotation):\n",
    "    #Load data\n",
    "    with open(path_to_annotation) as json_file:  \n",
    "        # Load json\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        # Print tags:\n",
    "        print('Tags:')\n",
    "        for tag in data['tags']:\n",
    "            print(tag)\n",
    "            \n",
    "        print('*******************')\n",
    "        print('Objects:')\n",
    "        #Print objects:\n",
    "        for object_dict in data['objects']:\n",
    "            print('Object type: {}\\nObject points: {}'.format(object_dict['classTitle'], \n",
    "                                                                   object_dict['points']['exterior']))\n",
    "            print('*******************')    \n",
    "            \n",
    "\n",
    "def display_annotations(path_to_annotation, image_dir, objectname, scale = 1):\n",
    "    #Load data\n",
    "    with open(path_to_annotation) as json_file:\n",
    "        \n",
    "        # Get name of the file\n",
    "        name = pathlib.PurePath(path_to_annotation).name.split('.')[0]\n",
    "        image = image_dir / (str(name) + '.png')\n",
    "\n",
    "        # Load image\n",
    "        original_image = cv2.imread(str(image))\n",
    "        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        annotated_image = original_image.copy()\n",
    "        \n",
    "        # Load json\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        # Draw fractures\n",
    "        for object_dict in data['objects']:\n",
    "            # Check if object is fracture\n",
    "            if object_dict['classTitle'] == objectname:\n",
    "               \n",
    "                # Get points and convert them to int for display purposes\n",
    "                top_left_point, bottom_right_point = object_dict['points']['exterior']\n",
    "                top_left_point = list(map(int,top_left_point))\n",
    "                bottom_right_point = list(map(int, bottom_right_point))\n",
    "                \n",
    "                # Draw points\n",
    "                cv2.rectangle(annotated_image, (top_left_point[0], top_left_point[1]), \n",
    "                              (bottom_right_point[0], bottom_right_point[1]), (0, 0, 255), 5)\n",
    "        \n",
    "        # Scale images for display purposes\n",
    "        original_image = cv2.resize(original_image, (0,0), fx=scale, fy=scale) \n",
    "        annotated_image = cv2.resize(annotated_image, (0,0), fx=scale, fy=scale) \n",
    "        \n",
    "        # Display images\n",
    "        cv2.imshow('Original', original_image)\n",
    "        cv2.imshow('Annotated', annotated_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function\n",
    "\n",
    "Select index name of the image/object that you want to preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags:\n",
      "{'name': 'ao_classification', 'value': '23r-M/3.1; 23u-E/7'}\n",
      "cast\n",
      "projection_lat\n",
      "side_right\n",
      "*******************\n",
      "Objects:\n",
      "Object type: text\n",
      "Object points: [[477.0, 58.0], [500.0, 88.0]]\n",
      "*******************\n",
      "Object type: fracture\n",
      "Object points: [[263.0, 367.0], [384.0, 439.0]]\n",
      "*******************\n",
      "Object type: axis\n",
      "Object points: [[302.0, 826.0], [363.0, 23.0]]\n",
      "*******************\n"
     ]
    }
   ],
   "source": [
    "# Select index of the image to preview\n",
    "index = 3823\n",
    "objectname = 'fracture'\n",
    "\n",
    "# To close images press any key\n",
    "parse_json(ann_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_annotations(ann_list[index], img_dir, objectname, scale = 0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix annotations containing only fracture boxes and labes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns the label and annotation for each instance\n",
    "def get_targets(path_to_annotation):\n",
    "    #Load data\n",
    "    targets = []\n",
    "    with open(path_to_annotation) as json_file:  \n",
    "        # Load json\n",
    "        data = json.load(json_file)\n",
    "        d = {}\n",
    "        \n",
    "        for object_dict in data['objects']:\n",
    "            # Check if object contains any fractures \n",
    "\n",
    "            box = []\n",
    "\n",
    "            if object_dict['classTitle'] == \"fracture\":\n",
    "                # Get points and convert them to int for display purposes\n",
    "                top_left_point, bottom_right_point = object_dict['points']['exterior']\n",
    "                top_left_point = list(map(int,top_left_point))\n",
    "                bottom_right_point = list(map(int, bottom_right_point))\n",
    "                box = (top_left_point+bottom_right_point)\n",
    "                d['boxes'] = torch.FloatTensor(box)\n",
    "                d['labels'] = \"fracture\"\n",
    "                targets.append(d)\n",
    "        \n",
    "        if not d:\n",
    "            d['labels'] = \"no_fracture\"\n",
    "            d['boxes'] =  torch.zeros(4)\n",
    "            targets.append(d)\n",
    "\n",
    "    return targets\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([213., 627., 288., 715.]), 'labels': 'fracture'},\n",
       " {'boxes': tensor([213., 627., 288., 715.]), 'labels': 'fracture'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(ann_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b00de58b91327812a3543b0a54b44486ebb363ab132784d28226d0402cd7527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
