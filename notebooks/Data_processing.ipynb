{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for data visualisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "from cv2 import cv2\n",
    "import torch\n",
    "from torchvision.ops import box_convert\n",
    "from typing import List, Dict\n",
    "from skimage.io import imread\n",
    "import pickle\n",
    "\n",
    "#for model\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead, RegionProposalNetwork\n",
    "import torch\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from cv2 import cv2\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#for model\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator, RPNHead, RegionProposalNetwork\n",
    "import torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations: 20327\n",
      "Number of images: 20327\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "from cv2 import cv2\n",
    "import json\n",
    "import pathlib\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "#Set path to root dir (wrist folder)\n",
    "root_dir = '../literature/Other/supervisely/'\n",
    "\n",
    "# Path to annotation dir\n",
    "ann_dir = os.listdir(root_dir + 'wrist/ann')\n",
    "\n",
    "# Path to image dir\n",
    "img_dir = os.listdir(root_dir + 'wrist/img')\n",
    "\n",
    "\n",
    "\n",
    "print('Number of annotations: {}'.format(len(ann_dir)))\n",
    "print('Number of images: {}'.format(len(img_dir)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The working directory of this project is: c:\\Users\\spiro\\OneDrive\\Υπολογιστής\\Thesis\\Project\\master_thesis_dtu\\notebooks\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('../')\n",
    "\n",
    "print(\"The working directory of this project is:\", os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images as RPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../literature/Other/supervisely/wrist/rpg_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20327/20327 [20:46<00:00, 16.31it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "root_dir = pathlib.Path('../literature/Other/supervisely/wrist/img/')\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(img_dir))):\n",
    "    img_path = os.path.join(root_dir,img_dir[idx])\n",
    "    ann_path = os.path.join('../literature/Other/supervisely/wrist/ann/',ann_dir[idx])\n",
    "\n",
    "\n",
    "    img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Convert the grayscale image to RGB and duplicate the grayscale channel\n",
    "    img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB) \n",
    "    cv2.imwrite(\"../literature/Other/supervisely/wrist/rpg_images/\" +img_dir[idx] , img)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pickles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def data_fix(img_list,ann_list):\n",
    "\n",
    "    root_dir = pathlib.Path('../literature/Other/supervisely')\n",
    "\n",
    "    for idx in tqdm(range(len(img_list))):\n",
    "        img_path = os.path.join(img_list[idx])\n",
    "        ann_path = os.path.join(ann_list[idx])\n",
    "        \n",
    "        #target = []\n",
    "        d = {}\n",
    "\n",
    "        box = []\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        area = []\n",
    "\n",
    "        classes = {'fracture' : 1, 'text' : 2}\n",
    "\n",
    "\n",
    "        name = pathlib.PurePath(ann_path).name.split('.')[0]\n",
    "\n",
    "        \n",
    "\n",
    "        with open(ann_path) as json_file:\n",
    "            \n",
    "            #Load the JSON file\n",
    "            data = json.load(json_file)\n",
    "\n",
    "\n",
    "        for object_dict in data['objects']:\n",
    "    \n",
    "            # Check if object contains any fractures\n",
    "\n",
    "            if object_dict['classTitle'] == \"text\" or object_dict['classTitle'] == \"fracture\":\n",
    "\n",
    "                # Get points and convert them to int for display purposes\n",
    "                top_left_point, bottom_right_point = object_dict['points']['exterior']\n",
    "                top_left_point = list(map(int,top_left_point))\n",
    "                bottom_right_point = list(map(int, bottom_right_point))\n",
    "                box = (top_left_point+bottom_right_point)\n",
    "                area.append((box[3] - box[1]) * (box[2] - box[0]))\n",
    "                label = classes[object_dict['classTitle']]\n",
    "                labels.append(label)\n",
    "                boxes.append(box)\n",
    "\n",
    "                # Check if the list is empty\n",
    "                if len(box) == 0:\n",
    "                    print(\"The list is empty!\")\n",
    "                \n",
    "\n",
    "        boxes = torch.FloatTensor(boxes)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        area = torch.as_tensor(area, dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "                \n",
    "        \n",
    "        d[\"boxes\"] = boxes\n",
    "        d[\"labels\"] = labels\n",
    "        d[\"image_id\"] = image_id\n",
    "        d[\"area\"] = area\n",
    "        \n",
    "\n",
    "        target = d\n",
    "\n",
    "        img = img_path\n",
    "\n",
    "        ready_data = {'image' : img,'target' : target}\n",
    "\n",
    "\n",
    "        path = os.path.join(root_dir,'wrist','train_pickles', name + '.pickle')\n",
    "\n",
    "        with open(path, 'wb') as handle:\n",
    "            pickle.dump(ready_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations: 20327\n",
      "Number of images: 20327\n"
     ]
    }
   ],
   "source": [
    "#Set path to root dir (wrist folder)\n",
    "root_dir = pathlib.Path('../literature/Other/supervisely')\n",
    "\n",
    "# Path to annotation dir\n",
    "ann_dir = pathlib.Path(root_dir, 'wrist/ann')\n",
    "\n",
    "# Path to image dir\n",
    "img_dir = pathlib.Path(root_dir, 'wrist/rpg_images')\n",
    "\n",
    "# Lists\n",
    "list_files = lambda start_dir: [str(item) for item in start_dir.iterdir()]\n",
    "ann_list = list_files(ann_dir)\n",
    "img_list = list_files(img_dir)\n",
    "\n",
    "print('Number of annotations: {}'.format(len(ann_list)))\n",
    "print('Number of images: {}'.format(len(img_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20327/20327 [00:07<00:00, 2873.61it/s]\n"
     ]
    }
   ],
   "source": [
    "data_fix(img_list,ann_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train-test folders \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"../literature/Other/supervisely/wrist/validation_pickles\")\n",
    "os.mkdir(\"../literature/Other/supervisely/wrist/test_pickles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVE THE TEST PICKLES TO ANOTHER FOLDER\n",
    "#Set path to root dir (wrist folder)\n",
    "root_dir = pathlib.Path('../literature/Other/supervisely')\n",
    "pickles = pathlib.Path(root_dir, 'wrist/train_pickles')\n",
    "pickle_list = os.listdir(pickles)\n",
    "\n",
    "\n",
    "random.seed(1234)\n",
    "test_images = random.sample(pickle_list, 3000)\n",
    "\n",
    "\n",
    "for pickle in test_images:\n",
    "    shutil.move('../literature/Other/supervisely/wrist/train_pickles/'+pickle, '../literature/Other/supervisely/wrist/test_pickles/'+pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVE SOME IMAGES FOR VALIDATION\n",
    "root_dir = pathlib.Path('../literature/Other/supervisely')\n",
    "pickles = pathlib.Path(root_dir, 'wrist/train_pickles')\n",
    "pickle_list = os.listdir(pickles)\n",
    "validation_images = random.sample(pickle_list, 1000)\n",
    "\n",
    "for pickle in validation_images:\n",
    "    shutil.move('../literature/Other/supervisely/wrist/train_pickles/'+pickle, '../literature/Other/supervisely/wrist/validation_pickles/'+pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16318\n",
      "1009\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('../literature/Other/supervisely/wrist/train_pickles')))\n",
    "print(len(os.listdir('../literature/Other/supervisely/wrist/validation_pickles')))\n",
    "print(len(os.listdir('../literature/Other/supervisely/wrist/test_pickles')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literature\\Other\\supervisely\\wrist\\rpg_images\\1590_0984643851_01_WRI-R1_M015.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '../literature/Other/supervisely/wrist/rpg_images/1590_0984643851_01_WRI-R1_M015.png'\n",
    "start_dir = '../'\n",
    "relative_path = os.path.relpath(path, start_dir)\n",
    "\n",
    "print(relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRayDataSet(torch.utils.data.Dataset):\n",
    "    \n",
    "\n",
    "     def __init__(self, root):\n",
    "        \n",
    "        self.root = root\n",
    "        self.instances = list(sorted(os.listdir(root)))\n",
    "        \n",
    "\n",
    "    \n",
    "     def __len__(self):\n",
    "        return len(self.instances) \n",
    "\n",
    "     def __getitem__(self,idx):\n",
    "        \n",
    "        instance = os.path.join(self.root, self.instances[idx])\n",
    "        \n",
    "\n",
    "        with open(instance, 'rb') as handle:\n",
    "            data = pickle.load(handle)\n",
    "\n",
    "        img_path = data['image']\n",
    "        #for linux to work\n",
    "        #start_dir = '../'\n",
    "        #img_path = os.path.relpath(img_path, start_dir)\n",
    "        #\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = T.ToTensor()(img).float()\n",
    "        target = data['target']\n",
    "\n",
    "\n",
    "        return img, target\n",
    "\n",
    "     def read_images(inp, tar):\n",
    "        return imread(inp), torch.load(tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train data\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.data.my_rpg_dataset import collate_fn\n",
    "train_dataset = XRayDataSet(pathlib.Path('../literature/Other/supervisely/wrist/validation_pickles'))\n",
    "training_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=0,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [00:37<00:00, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for imgs, annotations in tqdm(training_dataloader):\n",
    "     \n",
    "    imgs =list(img.to(\"cpu\") for img in imgs)\n",
    "    annotations = [{k: v.to(\"cpu\") for k, v in t.items()} for t in annotations]\n",
    "\n",
    "    # Check if the list is empty\n",
    "    for annotation in annotations:\n",
    "\n",
    "        if annotation['boxes'].numel() == 0:\n",
    "            continue\n",
    "    \n",
    "print(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = os.listdir('../literature/Other/supervisely/wrist/train_pickles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1413_0931733132_01_WRI-R2_M010.pickle'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3827]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../literature/Other/supervisely/wrist\\\\train_pickles\\\\1411_0517013711_01_WRI-L1_F017.pickle'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = os.path.join('../literature/Other/supervisely/wrist','train_pickles', instances[3823])\n",
    "instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(instance, 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': '..\\\\literature\\\\Other\\\\supervisely\\\\wrist\\\\rpg_images\\\\1411_0517013711_01_WRI-L1_F017.png',\n",
       " 'target': {'boxes': tensor([]),\n",
       "  'labels': tensor([], dtype=torch.int64),\n",
       "  'image_id': tensor([4722]),\n",
       "  'area': tensor([], dtype=torch.int64)}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b00de58b91327812a3543b0a54b44486ebb363ab132784d28226d0402cd7527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
